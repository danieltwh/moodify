{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import sys\n",
    "sys.path.insert(0, r\"C:\\Users\\veena\\OneDrive\\Desktop\\Nus\\Y4S2\\IS4242\\Project Actual\\moodify\\app\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import PIL \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDetector:\n",
    "\n",
    "  def __init__(self, trained_model_path):\n",
    "    self.model = tf.keras.models.load_model(trained_model_path)\n",
    "\n",
    "\n",
    "  #Should be the path to a cropped face, majority of the image should be face if not not likely to work well,\n",
    "  #(can easily be changed to batch of images if necessary)\n",
    "  def get_emotion(self, path_to_cropped_face):\n",
    "    pil_image = PIL.Image.open(path_to_cropped_face).convert('L')\n",
    "\n",
    "    #reshape the pil image\n",
    "    pil_image = pil_image.resize((48,48))\n",
    "\n",
    "    #convert to numpy array\n",
    "    to_model = np.array(pil_image).reshape((1,48,48,1))\n",
    "\n",
    "    #return the softmax output, in the following order: 1. Angry, 2. Disgust, 3. Fear, 4. Happy, 5. Neutral, 6. Sad\n",
    "    #7.Surprise\n",
    "\n",
    "    #For now, extract the 1d array of emotion probabilities as per the order above, can be changed as necessary if\n",
    "    #input is batch\n",
    "    pred = self.model(to_model).numpy()[0]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmotionDetector(r'../../app\\src/Mood_detector/trained_emotion.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68560475, 0.07280309, 0.12616083, 0.00609486, 0.01704143,\n",
       "       0.08538187, 0.00691313], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_emotion(r\"../../app\\src\\Mood_detector\\1.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
