{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "#from scipy.misc import imread\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data = keras.utils.image_dataset_from_directory(\n",
    "    directory='../../data/Faces',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=140,\n",
    "    image_size=(1000, 1000),\n",
    "    class_names = ['Happy', 'Neutral', 'Sad']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = YOLO(\"../../app/src/face_detection/model/yolov8n-face.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "numpy_generator = data.as_numpy_iterator()\n",
    "X, y = numpy_generator.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 face, 85.5ms\n",
      "Speed: 6.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 83.2ms\n",
      "Speed: 3.0ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 76.4ms\n",
      "Speed: 3.0ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 74.5ms\n",
      "Speed: 3.0ms preprocess, 74.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 75.0ms\n",
      "Speed: 3.0ms preprocess, 75.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 87.5ms\n",
      "Speed: 3.0ms preprocess, 87.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 106.5ms\n",
      "Speed: 4.0ms preprocess, 106.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 119.0ms\n",
      "Speed: 4.0ms preprocess, 119.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 93.5ms\n",
      "Speed: 4.0ms preprocess, 93.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 86.5ms\n",
      "Speed: 3.0ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 86.3ms\n",
      "Speed: 4.0ms preprocess, 86.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 89.3ms\n",
      "Speed: 3.0ms preprocess, 89.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 103.1ms\n",
      "Speed: 4.0ms preprocess, 103.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 99.5ms\n",
      "Speed: 4.0ms preprocess, 99.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 110.5ms\n",
      "Speed: 4.5ms preprocess, 110.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 82.5ms\n",
      "Speed: 3.0ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 85.1ms\n",
      "Speed: 3.0ms preprocess, 85.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 96.1ms\n",
      "Speed: 3.0ms preprocess, 96.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 90.1ms\n",
      "Speed: 3.0ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 83.4ms\n",
      "Speed: 3.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 99.2ms\n",
      "Speed: 4.0ms preprocess, 99.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 94.1ms\n",
      "Speed: 6.0ms preprocess, 94.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 86.5ms\n",
      "Speed: 4.0ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 84.3ms\n",
      "Speed: 3.0ms preprocess, 84.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 82.2ms\n",
      "Speed: 5.0ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 96.9ms\n",
      "Speed: 3.0ms preprocess, 96.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 92.1ms\n",
      "Speed: 3.0ms preprocess, 92.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 90.3ms\n",
      "Speed: 4.0ms preprocess, 90.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 93.5ms\n",
      "Speed: 3.0ms preprocess, 93.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 91.1ms\n",
      "Speed: 3.0ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 81.1ms\n",
      "Speed: 3.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 84.2ms\n",
      "Speed: 4.0ms preprocess, 84.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 86.6ms\n",
      "Speed: 3.0ms preprocess, 86.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 85.0ms\n",
      "Speed: 3.1ms preprocess, 85.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 90.5ms\n",
      "Speed: 3.0ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 95.0ms\n",
      "Speed: 3.5ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 103.5ms\n",
      "Speed: 4.0ms preprocess, 103.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 101.3ms\n",
      "Speed: 4.0ms preprocess, 101.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 107.5ms\n",
      "Speed: 8.0ms preprocess, 107.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 107.5ms\n",
      "Speed: 5.0ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 113.0ms\n",
      "Speed: 5.0ms preprocess, 113.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 112.5ms\n",
      "Speed: 6.0ms preprocess, 112.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 118.0ms\n",
      "Speed: 5.1ms preprocess, 118.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 122.2ms\n",
      "Speed: 5.0ms preprocess, 122.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 125.7ms\n",
      "Speed: 6.0ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 128.7ms\n",
      "Speed: 5.0ms preprocess, 128.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 121.8ms\n",
      "Speed: 7.0ms preprocess, 121.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 128.1ms\n",
      "Speed: 6.0ms preprocess, 128.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 126.5ms\n",
      "Speed: 7.0ms preprocess, 126.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 126.1ms\n",
      "Speed: 6.0ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 124.0ms\n",
      "Speed: 6.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 122.4ms\n",
      "Speed: 5.1ms preprocess, 122.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 123.6ms\n",
      "Speed: 6.0ms preprocess, 123.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 121.5ms\n",
      "Speed: 4.6ms preprocess, 121.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 112.1ms\n",
      "Speed: 5.0ms preprocess, 112.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 104.2ms\n",
      "Speed: 5.0ms preprocess, 104.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 112.1ms\n",
      "Speed: 5.0ms preprocess, 112.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 116.5ms\n",
      "Speed: 6.0ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 111.5ms\n",
      "Speed: 5.0ms preprocess, 111.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 106.5ms\n",
      "Speed: 4.0ms preprocess, 106.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 face, 102.5ms\n",
      "Speed: 5.0ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "X.nbytes\n",
    "\n",
    "num_faces = 0\n",
    "#create a dataset with cropped faces and its corresponding label\n",
    "X_cropped = []\n",
    "y_cropped = []\n",
    "for i in range(66):\n",
    "  #  print(i)\n",
    "    face = np.array(X[i], dtype = 'uint8')\n",
    "    faces = face_classifier.predict(face)\n",
    "    boxes = faces[0].boxes.xyxy.tolist()\n",
    "    if boxes:\n",
    "        num_faces += 1\n",
    "        #extract the face based on the output from the YOLOv8 model        \n",
    "        left, bottom, right, top = boxes[0]\n",
    "        cropped_face = face[int(bottom):int(top), int(left):int(right)]\n",
    "        #resize cropped face to a std shape, 100x100 for now but can adjust this\n",
    "        pil_face = Image.fromarray(np.uint8(cropped_face)).convert('L')\n",
    "        pil_face = pil_face.resize((48, 48))\n",
    "        numpy_cropped_face = np.array(pil_face)\n",
    "        #append this to the new list containing all cropped faces\n",
    "        X_cropped.append(numpy_cropped_face)\n",
    "        corresponding_label = y[i]\n",
    "        #append the labels to the new label list\n",
    "        y_cropped.append(corresponding_label)\n",
    "        #uncomment below lines of code to see the cropped face visualisation\n",
    "        \n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 48, 48)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cropped = np.array(X_cropped)\n",
    "y_cropped = np.array(y_cropped)\n",
    "X_cropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('trained_emotion_subclasses.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6307692307692307"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_cropped)\n",
    "\n",
    "\n",
    "\n",
    "sum(np.argmax(y_pred, axis = 1)==np.argmax(y_cropped, axis = 1))/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20\n",
       "0    19\n",
       "2     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.argmax(y_cropped[np.argmax(y_pred, axis = 1)==np.argmax(y_cropped, axis = 1)], axis = 1)).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
